# ğŸ“ Medya YÃ¶netimi ve Depolama Stratejisi

**Proje**: Affexai - Enterprise Customer Portal
**Tarih**: 2025-11-25
**Durum**: Production-ready strategy

---

## ğŸ¯ HEDEF

**GeliÅŸtirme ve deploy sÄ±rasÄ±nda yÃ¼klenen tÃ¼m medya dosyalarÄ±nÄ±n (gÃ¶rseller, PDF'ler, dÃ¶kÃ¼manlar) kalÄ±cÄ± olarak saklanmasÄ± ve asla kaybolmamasÄ±.**

---

## ğŸ“Š MEVCUT DURUM ANALÄ°ZÄ°

### âœ… Åu Anda YapÄ±lanlar:

**1. S3 Service Mevcut** ([apps/backend/src/modules/media/s3.service.ts](apps/backend/src/modules/media/s3.service.ts))
- AWS S3 SDK kullanÄ±lÄ±yor (`@aws-sdk/client-s3`)
- MinIO desteÄŸi var (development iÃ§in)
- Upload, delete, signed URL Ã¶zellikleri mevcut

**2. KullanÄ±m AlanlarÄ±**:
- âœ… Chat document upload (PDF, Word, Excel)
- âœ… Email marketing file upload (subscriber imports)
- âœ… CMS media management (planned)
- âœ… Certificate PDF generation
- âœ… User profile pictures (planned)

**3. Development Environment**:
```env
S3_ENDPOINT=http://localhost:9007
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_BUCKET_NAME=affexai-files
NEXT_PUBLIC_S3_PUBLIC_URL=http://localhost:9007/affexai-files
```

### âŒ Eksik Olanlar / Riskler:

1. **Production S3 config yok** - AWS credentials eksik
2. **Backup stratejisi yok** - S3 bucket backup planÄ± yok
3. **CDN entegrasyonu yok** - CloudFront veya benzeri yok
4. **Versioning yok** - Dosya versiyonlama aktif deÄŸil
5. **Lifecycle policies yok** - Eski dosyalarÄ±n arÅŸivleme stratejisi yok
6. **Database-S3 sync eksik** - DB'deki kayÄ±tlar ile S3'teki dosyalarÄ±n senkronizasyonu garanti deÄŸil

---

## ğŸ—ï¸ Ã–NERÄ°LEN MÄ°MARÄ°

### Option 1: AWS S3 (Ã–nerilen - Production Ready)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Production Setup                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Frontend (Next.js)                Backend (NestJS)
      â”‚                                  â”‚
      â”‚ (1) Upload Request              â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
      â”‚                                  â”‚
      â”‚                           (2) Generate           AWS S3 Bucket
      â”‚                           pre-signed URL    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  affexai-prod   â”‚
      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”‚                 â”‚
      â”‚ (3) Pre-signed URL               â”‚          â”‚  - Versioning   â”‚
      â”‚                                  â”‚          â”‚  - Encryption   â”‚
      â”‚ (4) Direct upload to S3          â”‚          â”‚  - Lifecycle    â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  - Replication  â”‚
      â”‚                                  â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ (5) Success, save metadata       â”‚                    â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                    â”‚
      â”‚                                  â”‚                    â”‚
      â”‚                           (6) Save DB record          â”‚
      â”‚                                  â”‚                    â”‚
      â”‚                                                       â”‚
      â”‚                                                       â–¼
      â”‚                                              CloudFront CDN
      â”‚                                         (Global Distribution)
      â”‚                                                       â”‚
      â”‚ (7) Serve files via CDN                              â”‚
      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantajlar**:
- âœ… 99.999999999% (11 nines) dayanÄ±klÄ±lÄ±k
- âœ… SÄ±nÄ±rsÄ±z depolama
- âœ… Global CDN entegrasyonu (CloudFront)
- âœ… Otomatik backup ve versioning
- âœ… Encryption at rest & in transit
- âœ… IAM-based gÃ¼venlik
- âœ… Cost-effective (pay as you go)

**Maliyetler** (Ã–rnek - us-east-1):
- Storage: $0.023/GB/month (ilk 50 TB)
- PUT requests: $0.005/1000 requests
- GET requests: $0.0004/1000 requests
- Data transfer: $0.09/GB (out to internet)
- **Tahmini maliyet**: ~$10-50/month (10-100 GB storage)

---

### Option 2: Cloudflare R2 (Alternatif - Daha Ucuz)

**Avantajlar**:
- âœ… S3-compatible API (kod deÄŸiÅŸikliÄŸi minimal)
- âœ… **ZERO egress fees** (data transfer Ã¼cretsiz!)
- âœ… Cloudflare CDN entegrasyonu
- âœ… $0.015/GB/month (S3'ten %35 daha ucuz)

**Maliyetler**:
- Storage: $0.015/GB/month
- Class A ops (write): $4.50/million
- Class B ops (read): $0.36/million
- **NO DATA TRANSFER FEES** ğŸ‰
- **Tahmini maliyet**: ~$5-20/month (10-100 GB storage)

**Kod deÄŸiÅŸikliÄŸi**:
```typescript
// Sadece endpoint deÄŸiÅŸir
S3_ENDPOINT=https://YOUR_ACCOUNT_ID.r2.cloudflarestorage.com
S3_REGION=auto
// Credentials Cloudflare'den alÄ±nÄ±r
```

---

### Option 3: MinIO Self-Hosted (Budget Friendly)

**Avantajlar**:
- âœ… S3-compatible API
- âœ… Tam kontrol
- âœ… Tek seferlik maliyet (server)
- âœ… GDPR compliance (data in your hands)

**Dezavantajlar**:
- âŒ Kendi backup'Ä±nÄ±zÄ± yÃ¶netmelisiniz
- âŒ CDN entegrasyonu manuel
- âŒ Scaling manuel
- âŒ BakÄ±m ve monitoring sorumluluÄŸu sizde

**KullanÄ±m Senaryosu**: KÃ¼Ã§Ã¼k-orta Ã¶lÃ§ek, budget kÄ±sÄ±tlÄ±, GDPR Ã¶nemli

---

## ğŸš€ PRODUCTION DEPLOYMENT STRATEJÄ°SÄ°

### 1ï¸âƒ£ AWS S3 Production Setup (Ã–nerilen)

#### A. AWS Console Ãœzerinden HazÄ±rlÄ±k

```bash
# 1. S3 Bucket oluÅŸtur
Bucket name: affexai-production-media
Region: eu-central-1 (Frankfurt - GDPR compliant)
Block public access: OFF (public read iÃ§in)

# 2. Versioning aktif et
Properties â†’ Versioning â†’ Enable

# 3. Encryption aktif et
Properties â†’ Default encryption â†’ AES-256

# 4. Lifecycle policy oluÅŸtur
Management â†’ Lifecycle rules â†’ Create rule
Name: archive-old-files
Transitions:
  - After 90 days â†’ Glacier Instant Retrieval
  - After 365 days â†’ Glacier Deep Archive

# 5. Replication kuralÄ± (optional - kritik iÃ§in)
Management â†’ Replication â†’ Create rule
Destination: affexai-backup-media (farklÄ± region)

# 6. CloudFront distribution oluÅŸtur
CloudFront â†’ Create distribution
Origin: affexai-production-media.s3.eu-central-1.amazonaws.com
Cache behavior: Cache based on query strings
SSL certificate: Use ACM certificate
```

#### B. IAM User ve Permissions

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:DeleteObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::affexai-production-media/*",
        "arn:aws:s3:::affexai-production-media"
      ]
    }
  ]
}
```

**IAM User oluÅŸtur**:
```
Username: affexai-backend-service
Access type: Programmatic access
Attach policy: affexai-s3-access (yukarÄ±daki policy)
```

#### C. Backend Environment Variables

**Production `.env`**:
```env
# AWS S3 Production
S3_ENDPOINT=https://s3.eu-central-1.amazonaws.com
S3_REGION=eu-central-1
S3_BUCKET_NAME=affexai-production-media
S3_ACCESS_KEY=AKIA******************  # IAM user access key
S3_SECRET_KEY=****************************************  # IAM user secret key

# CloudFront CDN (public URL)
NEXT_PUBLIC_S3_PUBLIC_URL=https://d123456789abcd.cloudfront.net
```

**Staging `.env`**:
```env
# AWS S3 Staging
S3_ENDPOINT=https://s3.eu-central-1.amazonaws.com
S3_REGION=eu-central-1
S3_BUCKET_NAME=affexai-staging-media
S3_ACCESS_KEY=AKIA******************
S3_SECRET_KEY=****************************************
NEXT_PUBLIC_S3_PUBLIC_URL=https://d987654321zyxw.cloudfront.net
```

**Development (MinIO - mevcut)**:
```env
S3_ENDPOINT=http://localhost:9007
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_BUCKET_NAME=affexai-files
NEXT_PUBLIC_S3_PUBLIC_URL=http://localhost:9007/affexai-files
```

---

### 2ï¸âƒ£ Database ve S3 Senkronizasyonu

**Problem**: DB'de kayÄ±t var ama S3'te dosya silinmiÅŸ olabilir (veya tersi)

**Ã‡Ã¶zÃ¼m**: Media tracking tablosu ve scheduled job

#### A. Media Tracking Entity OluÅŸtur

**Dosya**: `apps/backend/src/modules/media/entities/media-file.entity.ts`

```typescript
import { Entity, PrimaryGeneratedColumn, Column, CreateDateColumn, UpdateDateColumn, Index } from 'typeorm';

@Entity('media_files')
@Index(['s3Key', 'isDeleted'])
export class MediaFile {
  @PrimaryGeneratedColumn('uuid')
  id: string;

  @Column()
  @Index()
  s3Key: string; // S3'teki dosya key'i (Ã¶rn: "1732550000-image.png")

  @Column()
  originalFilename: string;

  @Column()
  mimeType: string;

  @Column({ type: 'bigint' })
  fileSize: number; // bytes

  @Column()
  s3Url: string; // Full URL (CloudFront veya S3)

  @Column({ type: 'varchar', nullable: true })
  cdnUrl: string | null; // CloudFront URL (varsa)

  @Column({ type: 'varchar', nullable: true })
  uploadedBy: string | null; // User ID

  @Column({ type: 'varchar', nullable: true })
  relatedEntity: string | null; // 'chat_document', 'cms_image', 'certificate', vb.

  @Column({ type: 'varchar', nullable: true })
  relatedEntityId: string | null; // Ä°lgili entity'nin ID'si

  @Column({ type: 'boolean', default: false })
  @Index()
  isDeleted: boolean; // Soft delete flag

  @Column({ type: 'timestamp', nullable: true })
  lastVerifiedAt: Date | null; // Son S3 verification tarihi

  @Column({ type: 'boolean', default: true })
  existsInS3: boolean; // S3'te dosya var mÄ±? (verification sonucu)

  @CreateDateColumn()
  createdAt: Date;

  @UpdateDateColumn()
  updatedAt: Date;

  @Column({ type: 'timestamp', nullable: true })
  deletedAt: Date | null; // Soft delete timestamp
}
```

#### B. Enhanced S3 Service (Tracking ile)

**Dosya**: `apps/backend/src/modules/media/s3.service.ts` (gÃ¼ncellenmiÅŸ)

```typescript
import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { InjectRepository } from '@nestjs/typeorm';
import { Repository } from 'typeorm';
import { MediaFile } from './entities/media-file.entity';
import {
  S3Client,
  PutObjectCommand,
  DeleteObjectCommand,
  GetObjectCommand,
  HeadObjectCommand, // Dosya varlÄ±ÄŸÄ±nÄ± kontrol iÃ§in
} from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';

@Injectable()
export class S3Service {
  private readonly logger = new Logger(S3Service.name);
  private readonly s3Client: S3Client | null = null;
  private readonly bucketName: string | null = null;
  private readonly isConfigured: boolean = false;

  constructor(
    private readonly configService: ConfigService,
    @InjectRepository(MediaFile)
    private readonly mediaFileRepository: Repository<MediaFile>,
  ) {
    // ... existing initialization ...
  }

  /**
   * Upload file with database tracking
   */
  async uploadFile(
    fileName: string,
    fileBuffer: Buffer,
    mimeType: string,
    uploadedBy?: string,
    relatedEntity?: string,
    relatedEntityId?: string,
  ): Promise<{ url: string; mediaFile: MediaFile }> {
    if (!this.isConfigured || !this.s3Client || !this.bucketName) {
      throw new Error('S3 service is not configured');
    }

    try {
      const key = `${Date.now()}-${fileName}`;

      // 1. Upload to S3
      const command = new PutObjectCommand({
        Bucket: this.bucketName,
        Key: key,
        Body: fileBuffer,
        ContentType: mimeType,
      });

      await this.s3Client.send(command);

      // 2. Get URLs
      const s3Url = `${this.configService.get<string>('S3_ENDPOINT')}/${this.bucketName}/${key}`;
      const cdnUrl = this.configService.get<string>('NEXT_PUBLIC_S3_PUBLIC_URL')
        ? `${this.configService.get<string>('NEXT_PUBLIC_S3_PUBLIC_URL')}/${key}`
        : null;

      // 3. Save to database for tracking
      const mediaFile = this.mediaFileRepository.create({
        s3Key: key,
        originalFilename: fileName,
        mimeType,
        fileSize: fileBuffer.length,
        s3Url,
        cdnUrl,
        uploadedBy,
        relatedEntity,
        relatedEntityId,
        lastVerifiedAt: new Date(),
        existsInS3: true,
      });

      await this.mediaFileRepository.save(mediaFile);

      this.logger.log(`File uploaded and tracked: ${key}`);

      return { url: cdnUrl || s3Url, mediaFile };
    } catch (error) {
      this.logger.error(`Failed to upload file: ${error.message}`);
      throw error;
    }
  }

  /**
   * Delete file with database tracking
   */
  async deleteFile(key: string, hardDelete: boolean = false): Promise<void> {
    if (!this.isConfigured || !this.s3Client || !this.bucketName) {
      throw new Error('S3 service is not configured');
    }

    try {
      // 1. Find in database
      const mediaFile = await this.mediaFileRepository.findOne({
        where: { s3Key: key, isDeleted: false },
      });

      if (!mediaFile) {
        this.logger.warn(`Media file not found in database: ${key}`);
      }

      if (hardDelete) {
        // Hard delete: Remove from S3 and database
        const command = new DeleteObjectCommand({
          Bucket: this.bucketName,
          Key: key,
        });

        await this.s3Client.send(command);

        if (mediaFile) {
          await this.mediaFileRepository.remove(mediaFile);
        }

        this.logger.log(`File hard deleted: ${key}`);
      } else {
        // Soft delete: Mark as deleted in database, keep in S3
        if (mediaFile) {
          mediaFile.isDeleted = true;
          mediaFile.deletedAt = new Date();
          await this.mediaFileRepository.save(mediaFile);
        }

        this.logger.log(`File soft deleted: ${key}`);
      }
    } catch (error) {
      this.logger.error(`Failed to delete file: ${error.message}`);
      throw error;
    }
  }

  /**
   * Verify file exists in S3
   */
  async verifyFileExists(key: string): Promise<boolean> {
    if (!this.isConfigured || !this.s3Client || !this.bucketName) {
      return false;
    }

    try {
      const command = new HeadObjectCommand({
        Bucket: this.bucketName,
        Key: key,
      });

      await this.s3Client.send(command);
      return true;
    } catch (error) {
      if (error.name === 'NotFound') {
        return false;
      }
      throw error;
    }
  }

  /**
   * Sync database with S3 (scheduled job)
   */
  async syncDatabaseWithS3(): Promise<{ checked: number; missing: number; fixed: number }> {
    const mediaFiles = await this.mediaFileRepository.find({
      where: { isDeleted: false },
    });

    let checked = 0;
    let missing = 0;
    let fixed = 0;

    for (const file of mediaFiles) {
      checked++;

      const exists = await this.verifyFileExists(file.s3Key);

      if (!exists && file.existsInS3) {
        // Dosya S3'te yok ama DB'de var olarak iÅŸaretli
        file.existsInS3 = false;
        await this.mediaFileRepository.save(file);
        missing++;
        this.logger.warn(`File missing in S3: ${file.s3Key}`);
      } else if (exists && !file.existsInS3) {
        // Dosya S3'te var ama DB'de yok olarak iÅŸaretli
        file.existsInS3 = true;
        file.lastVerifiedAt = new Date();
        await this.mediaFileRepository.save(file);
        fixed++;
        this.logger.log(`File status fixed: ${file.s3Key}`);
      } else if (exists) {
        // Her ÅŸey yolunda, sadece verification tarihini gÃ¼ncelle
        file.lastVerifiedAt = new Date();
        await this.mediaFileRepository.save(file);
      }
    }

    this.logger.log(
      `S3 sync completed: ${checked} checked, ${missing} missing, ${fixed} fixed`,
    );

    return { checked, missing, fixed };
  }

  // ... existing methods (getSignedUrl, etc.) ...
}
```

#### C. Scheduled Sync Job

**Dosya**: `apps/backend/src/modules/media/media-sync.service.ts`

```typescript
import { Injectable, Logger } from '@nestjs/common';
import { Cron, CronExpression } from '@nestjs/schedule';
import { S3Service } from './s3.service';

@Injectable()
export class MediaSyncService {
  private readonly logger = new Logger(MediaSyncService.name);

  constructor(private readonly s3Service: S3Service) {}

  /**
   * Her gece 3:00'te S3 ve database senkronizasyonu yap
   */
  @Cron('0 3 * * *', {
    name: 'media-s3-sync',
    timeZone: 'Europe/Istanbul',
  })
  async handleMediaSync() {
    this.logger.log('Starting scheduled media-S3 sync...');

    try {
      const result = await this.s3Service.syncDatabaseWithS3();

      this.logger.log(
        `Media sync completed: ${result.checked} files checked, ` +
        `${result.missing} missing in S3, ${result.fixed} status fixed`,
      );

      // EÄŸer Ã§ok fazla eksik dosya varsa alert gÃ¶nder
      if (result.missing > 10) {
        this.logger.error(
          `âš ï¸ WARNING: ${result.missing} files are missing in S3! ` +
          `This may indicate a backup/restore issue.`,
        );
        // TODO: Send email alert or Slack notification
      }
    } catch (error) {
      this.logger.error(`Media sync failed: ${error.message}`, error.stack);
    }
  }
}
```

---

### 3ï¸âƒ£ Backup ve Disaster Recovery Stratejisi

#### A. AWS S3 Cross-Region Replication

**Setup** (AWS Console):
```
Primary bucket: affexai-production-media (eu-central-1)
Replica bucket: affexai-backup-media (us-east-1)

Replication rule:
- Replicate all objects
- Destination storage class: Standard-IA (daha ucuz)
- Replication time control: Enabled (15 dakikada replica)
```

**Avantajlar**:
- âœ… Otomatik real-time backup
- âœ… FarklÄ± region (disaster recovery)
- âœ… Versioning ile birlikte Ã§alÄ±ÅŸÄ±r
- âœ… YanlÄ±ÅŸlÄ±kla silmelere karÅŸÄ± koruma

#### B. Automated Backup Script (Alternative)

**Dosya**: `scripts/backup-s3-to-local.sh`

```bash
#!/bin/bash
# S3 Bucket'Ä± yerel sunucuya backup al

BUCKET_NAME="affexai-production-media"
BACKUP_DIR="/backups/s3-media"
DATE=$(date +%Y-%m-%d)

echo "Starting S3 backup: $BUCKET_NAME -> $BACKUP_DIR/$DATE"

# AWS CLI ile tÃ¼m bucket'Ä± sync et
aws s3 sync s3://$BUCKET_NAME $BACKUP_DIR/$DATE \
  --region eu-central-1 \
  --storage-class STANDARD_IA

echo "Backup completed!"

# 90 gÃ¼nden eski backup'larÄ± sil
find $BACKUP_DIR -type d -mtime +90 -exec rm -rf {} \;
```

**Cron job** (her gece):
```cron
0 2 * * * /path/to/scripts/backup-s3-to-local.sh >> /var/log/s3-backup.log 2>&1
```

---

### 4ï¸âƒ£ Migration Stratejisi (Development â†’ Production)

#### A. MinIO'dan AWS S3'e Migrate

**Script**: `scripts/migrate-minio-to-s3.ts`

```typescript
import { S3Client, ListObjectsV2Command, GetObjectCommand, PutObjectCommand } from '@aws-sdk/client-s3';
import { Readable } from 'stream';

async function migrateMinioToS3() {
  // MinIO client (source)
  const minioClient = new S3Client({
    endpoint: 'http://localhost:9007',
    region: 'us-east-1',
    credentials: {
      accessKeyId: 'minioadmin',
      secretAccessKey: 'minioadmin',
    },
    forcePathStyle: true,
  });

  // AWS S3 client (destination)
  const s3Client = new S3Client({
    endpoint: 'https://s3.eu-central-1.amazonaws.com',
    region: 'eu-central-1',
    credentials: {
      accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
      secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
    },
  });

  const sourceBucket = 'affexai-files';
  const destBucket = 'affexai-production-media';

  console.log(`Starting migration: ${sourceBucket} -> ${destBucket}`);

  // List all objects in MinIO
  const listCommand = new ListObjectsV2Command({
    Bucket: sourceBucket,
  });

  const { Contents } = await minioClient.send(listCommand);

  if (!Contents || Contents.length === 0) {
    console.log('No files to migrate');
    return;
  }

  console.log(`Found ${Contents.length} files to migrate`);

  let migrated = 0;
  let failed = 0;

  for (const object of Contents) {
    try {
      console.log(`Migrating: ${object.Key}`);

      // Get from MinIO
      const getCommand = new GetObjectCommand({
        Bucket: sourceBucket,
        Key: object.Key!,
      });

      const { Body, ContentType } = await minioClient.send(getCommand);

      // Convert stream to buffer
      const chunks: Buffer[] = [];
      for await (const chunk of Body as Readable) {
        chunks.push(chunk);
      }
      const buffer = Buffer.concat(chunks);

      // Put to S3
      const putCommand = new PutObjectCommand({
        Bucket: destBucket,
        Key: object.Key!,
        Body: buffer,
        ContentType,
      });

      await s3Client.send(putCommand);

      migrated++;
      console.log(`âœ… Migrated: ${object.Key}`);
    } catch (error) {
      failed++;
      console.error(`âŒ Failed: ${object.Key}`, error.message);
    }
  }

  console.log(`\nMigration completed: ${migrated} migrated, ${failed} failed`);
}

migrateMinioToS3().catch(console.error);
```

**KullanÄ±m**:
```bash
cd apps/backend
npx ts-node ../../scripts/migrate-minio-to-s3.ts
```

---

## ğŸ“ DOCKER COMPOSE Ä°YÄ°LEÅTÄ°RMELERÄ°

**Dosya**: `docker/docker-compose.yml` (gÃ¼ncellenmiÅŸ)

```yaml
version: '3.8'

services:
  # ... postgres, redis ...

  minio:
    image: minio/minio:latest
    container_name: affexai-minio
    ports:
      - "9007:9000"  # API
      - "9008:9001"  # Console
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio-data:/data  # âš ï¸ IMPORTANT: Persistent volume
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  minio-data:  # âš ï¸ IMPORTANT: MinIO volume - veriler burada saklanÄ±r
    driver: local
```

**Host Backup** (Optional - MinIO data'yÄ± local'e backup):
```yaml
    volumes:
      - ./data/minio:/data  # Local directory'e mount et
```

Bu ÅŸekilde `docker/data/minio/` klasÃ¶rÃ¼ local makinede olur, container silinse bile veriler kaybolmaz.

---

## ğŸ”’ GÃœVENLÄ°K Ã–NERÄ°LERÄ°

### 1. S3 Bucket Policies

**Public read iÃ§in** (sadece gerekli dosyalar):
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "PublicReadGetObject",
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::affexai-production-media/public/*"
    }
  ]
}
```

**Folder yapÄ±sÄ±**:
```
affexai-production-media/
  â”œâ”€â”€ public/          # Public accessible (CMS images, logos)
  â”‚   â”œâ”€â”€ cms/
  â”‚   â”œâ”€â”€ products/
  â”‚   â””â”€â”€ logos/
  â”œâ”€â”€ private/         # Private (user documents, PDFs)
  â”‚   â”œâ”€â”€ chat-documents/
  â”‚   â”œâ”€â”€ certificates/
  â”‚   â””â”€â”€ user-uploads/
  â””â”€â”€ temp/            # Temporary (auto-delete after 7 days)
```

### 2. CORS Configuration

```json
[
  {
    "AllowedHeaders": ["*"],
    "AllowedMethods": ["GET", "PUT", "POST", "DELETE"],
    "AllowedOrigins": [
      "https://affexai.com",
      "https://www.affexai.com",
      "https://admin.affexai.com"
    ],
    "ExposeHeaders": ["ETag"]
  }
]
```

### 3. Encryption

- âœ… Server-side encryption (AES-256)
- âœ… HTTPS-only access
- âœ… Pre-signed URLs for private files (1 hour expiry)

---

## ğŸ’° MALIYET ANALÄ°ZÄ°

### Senaryo 1: KÃ¼Ã§Ã¼k Proje (10 GB storage, 1000 requests/month)

**AWS S3**:
- Storage: 10 GB Ã— $0.023 = $0.23/month
- PUT: 1000 Ã— $0.005/1000 = $0.005/month
- GET: 10,000 Ã— $0.0004/1000 = $0.004/month
- Data transfer: 50 GB Ã— $0.09 = $4.50/month
- **Total: ~$5/month**

**Cloudflare R2**:
- Storage: 10 GB Ã— $0.015 = $0.15/month
- Class A: 1000 Ã— $4.50/1M = $0.0045/month
- Class B: 10,000 Ã— $0.36/1M = $0.0036/month
- Data transfer: **$0** (FREE!)
- **Total: ~$0.16/month** ğŸ‰

### Senaryo 2: Orta Proje (100 GB storage, 100K requests/month)

**AWS S3**:
- Storage: 100 GB Ã— $0.023 = $2.30/month
- Requests: ~$0.50/month
- Data transfer: 500 GB Ã— $0.09 = $45/month
- **Total: ~$48/month**

**Cloudflare R2**:
- Storage: 100 GB Ã— $0.015 = $1.50/month
- Requests: ~$0.45/month
- Data transfer: **$0**
- **Total: ~$2/month** ğŸ‰

**SONUÃ‡**: Cloudflare R2, data transfer nedeniyle AWS S3'ten 10-20x daha ucuz!

---

## âœ… CHECKLIST: PRODUCTION HAZIRLIÄI

### Development â†’ Staging â†’ Production Migration

- [ ] **1. AWS/Cloudflare account setup**
  - [ ] S3 bucket oluÅŸtur (production + staging)
  - [ ] IAM user ve credentials oluÅŸtur
  - [ ] Bucket policies ayarla
  - [ ] CORS configuration

- [ ] **2. Backend configuration**
  - [ ] Production `.env` dosyasÄ± hazÄ±rla (S3 credentials)
  - [ ] Staging `.env` dosyasÄ± hazÄ±rla
  - [ ] MediaFile entity oluÅŸtur (database tracking)
  - [ ] S3Service gÃ¼ncelle (tracking ile)
  - [ ] MediaSyncService ekle (scheduled job)
  - [ ] Migration script hazÄ±rla (MinIO â†’ S3)

- [ ] **3. Database migration**
  - [ ] `media_files` tablosu migration'Ä± oluÅŸtur
  - [ ] Production DB'de migration'Ä± Ã§alÄ±ÅŸtÄ±r
  - [ ] Existing S3 files iÃ§in bulk insert (eÄŸer varsa)

- [ ] **4. Data migration**
  - [ ] MinIO'daki mevcut dosyalarÄ± S3'e migrate et
  - [ ] Database kayÄ±tlarÄ±nÄ± gÃ¼ncelle (yeni URLs)
  - [ ] Verification job Ã§alÄ±ÅŸtÄ±r

- [ ] **5. CDN setup** (optional ama Ã¶nerilen)
  - [ ] CloudFront distribution oluÅŸtur
  - [ ] SSL certificate (ACM)
  - [ ] Cache policies
  - [ ] Origin access identity

- [ ] **6. Backup stratejisi**
  - [ ] S3 versioning aktif
  - [ ] Cross-region replication (optional)
  - [ ] Lifecycle policies
  - [ ] Backup script (optional)

- [ ] **7. Monitoring & alerts**
  - [ ] S3 bucket metrics (CloudWatch)
  - [ ] MediaSyncService logs
  - [ ] Alert for missing files (>10)
  - [ ] Cost alerts (AWS Budgets)

- [ ] **8. Testing**
  - [ ] Upload test (backend â†’ S3)
  - [ ] Download test (CDN URL)
  - [ ] Delete test (soft + hard)
  - [ ] Verification job test
  - [ ] Load test (100+ concurrent uploads)

---

## ğŸš¨ FELAKET KURTARMA (DISASTER RECOVERY)

### Senaryo 1: S3 Bucket YanlÄ±ÅŸlÄ±kla Silindi

**Ã‡Ã¶zÃ¼m**: Cross-region replication aktifse:
1. Replica bucket'tan restore et
2. Bucket policy'leri yeniden kur
3. CloudFront distribution'Ä± gÃ¼ncelle

**Prevention**:
- âœ… MFA Delete aktif et (kritik bucket iÃ§in)
- âœ… IAM permissions sÄ±kÄ± tut (sadece backend service)
- âœ… Versioning + Lifecycle policies

### Senaryo 2: Database Corrupt Oldu, Media KayÄ±tlarÄ± Kayboldu

**Ã‡Ã¶zÃ¼m**:
1. S3'teki tÃ¼m dosyalarÄ± listele (AWS CLI)
2. Database'i en son backup'tan restore et
3. MediaSyncService Ã§alÄ±ÅŸtÄ±r (S3 â†’ DB senkronizasyonu)

```bash
# S3'teki tÃ¼m dosyalarÄ± listele
aws s3 ls s3://affexai-production-media --recursive > s3-files.txt

# Database'e bulk insert script Ã§alÄ±ÅŸtÄ±r
node scripts/rebuild-media-table-from-s3.js
```

### Senaryo 3: Provider DeÄŸiÅŸikliÄŸi (AWS â†’ Cloudflare R2)

**Migration plan**:
1. R2 bucket oluÅŸtur
2. AWS S3'ten R2'ye migration script Ã§alÄ±ÅŸtÄ±r (rclone)
3. Backend'de endpoint'i deÄŸiÅŸtir
4. Parallel Ã§alÄ±ÅŸtÄ±r (1 hafta AWS + R2 ikisi de aktif)
5. Verification sonrasÄ± AWS'i kapat

**rclone kullanÄ±mÄ±**:
```bash
rclone sync s3:affexai-production-media r2:affexai-production-media \
  --progress \
  --checksum \
  --log-file=migration.log
```

---

## ğŸ“š EK KAYNAKLAR

### AWS S3 Best Practices
- https://docs.aws.amazon.com/AmazonS3/latest/userguide/best-practices.html
- https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html

### Cloudflare R2
- https://developers.cloudflare.com/r2/
- https://blog.cloudflare.com/introducing-r2/

### MinIO Documentation
- https://min.io/docs/minio/linux/index.html

---

## ğŸ¯ Ã–NERÄ°: Hemen YapÄ±lmasÄ± Gerekenler

1. âœ… **MediaFile entity oluÅŸtur** - Database tracking iÃ§in
2. âœ… **S3Service gÃ¼ncelle** - Tracking ile entegre et
3. âœ… **Production S3 bucket kur** - AWS veya Cloudflare R2
4. âœ… **MinIO â†’ S3 migration script** - Mevcut dosyalarÄ± taÅŸÄ±
5. âœ… **MediaSyncService ekle** - Otomatik senkronizasyon
6. âœ… **Backup stratejisi kur** - Cross-region replication veya scheduled backup

**Ã–ncelik**: High - Production'a geÃ§meden Ã¶nce mutlaka yapÄ±lmalÄ±!

---

**HazÄ±rlayan**: Claude Code (AI Assistant)
**Tarih**: 2025-11-25
**Versiyon**: 1.0
